{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "555ccb10",
   "metadata": {},
   "source": [
    "## This notebook will give you a walk through of nltk preprocessing library to preprocess twitter sentiment analysis data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf2f47f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import random\n",
    "from nltk.corpus import twitter_samples\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931b0ca0",
   "metadata": {},
   "source": [
    "## download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c5f8dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download(\"twitter_samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0269e5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_samples = twitter_samples.strings(\"positive_tweets.json\")\n",
    "negative_samples = twitter_samples.strings(\"negative_tweets.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f9e58b",
   "metadata": {},
   "source": [
    "## download stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efd57e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/deepak/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a782743b",
   "metadata": {},
   "source": [
    "## remove hyper links, hashtags and RT which can occur commonly in many tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4f11af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = positive_samples[2277]\n",
    "# remove old style retweet text \"RT\"\n",
    "tweet2 = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "# remove hyperlinks\n",
    "tweet2 = re.sub(r'https?://[^\\s\\n\\r]+', '', tweet2)\n",
    "# remove hashtags\n",
    "# only removing the hash # sign from the word\n",
    "tweet2 = re.sub(r'#', '', tweet2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfab9aa",
   "metadata": {},
   "source": [
    "## tokenize the tweets into tokens or words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0aa3061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My beautiful sunflowers on a sunny Friday morning off :) sunflowers favourites happy Friday off… \n",
      "['my', 'beautiful', 'sunflowers', 'on', 'a', 'sunny', 'friday', 'morning', 'off', ':)', 'sunflowers', 'favourites', 'happy', 'friday', 'off', '…']\n"
     ]
    }
   ],
   "source": [
    "tokenizer = TweetTokenizer(preserve_case = False, strip_handles = True, reduce_len = True)\n",
    "tweet_tokens = tokenizer.tokenize(tweet2)\n",
    "print(tweet2)\n",
    "print(tweet_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c178b6d2",
   "metadata": {},
   "source": [
    "## remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6e906b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed words\n",
      "['beautiful', 'sunflowers', 'sunny', 'friday', 'morning', ':)', 'sunflowers', 'favourites', 'happy', 'friday', '…']\n"
     ]
    }
   ],
   "source": [
    "stop_words_english = stopwords.words(\"english\")\n",
    "tweet_clean = []\n",
    "for word in tweet_tokens:\n",
    "    if (word not in stop_words_english and word not in string.punctuation):\n",
    "        tweet_clean.append(word)\n",
    "print(\"removed words\")\n",
    "print(tweet_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b8b922",
   "metadata": {},
   "source": [
    "## stemming using the porter stemmer to replace the words by thier stem of common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6247d030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stemmed words:\n",
      "['beauti', 'sunflow', 'sunni', 'friday', 'morn', ':)', 'sunflow', 'favourit', 'happi', 'friday', '…']\n"
     ]
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "tweets_stem = []\n",
    "for word in tweet_clean:\n",
    "    stem_word = stemmer.stem(word)\n",
    "    tweets_stem.append(stem_word)\n",
    "\n",
    "print(\"stemmed words:\")\n",
    "print(tweets_stem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a732a0f6",
   "metadata": {},
   "source": [
    "## A made a preprocess tweet function which you can use to preprocess tweets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "48055bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweet(tweet):\n",
    "    stemmer = PorterStemmer()\n",
    "    stopwords_english = stopwords.words('english')\n",
    "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "    tweet = re.sub(r'https?://[^\\s\\n\\r]+', '', tweet)\n",
    "    tweet = re.sub(r'#', '', tweet)\n",
    "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,\n",
    "                               reduce_len=True)\n",
    "    tweet_tokens = tokenizer.tokenize(tweet)\n",
    "\n",
    "    tweets_clean = []\n",
    "    for word in tweet_tokens:\n",
    "        if (word not in stopwords_english and  # remove stopwords\n",
    "                word not in string.punctuation):  # remove punctuation\n",
    "            stem_word = stemmer.stem(word)  # stemming word\n",
    "            tweets_clean.append(stem_word)\n",
    "\n",
    "    return tweets_clean"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
